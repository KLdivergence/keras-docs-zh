<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>激活函数 Activations - Keras 中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u6fc0\u6d3b\u51fd\u6570 Activations";
    var mkdocs_page_input_path = "activations.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Keras 中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">主页</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../why-use-keras/">为什么选择 Keras?</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">快速开始</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../getting-started/sequential-model-guide/">Sequential 顺序模型指引</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/functional-api-guide/">函数式 API 指引</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/faq/">FAQ 常见问题解答</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">模型</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../models/about-keras-models/">关于 Keras 模型</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/sequential/">Sequential 顺序模型 API</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/model/">函数式 API</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Layers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../layers/about-keras-layers/">关于 Keras 网络层</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/core/">核心网络层</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/convolutional/">卷积层 Convolutional</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/pooling/">池化层 Pooling</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/local/">局部连接层 Locally-connected</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/recurrent/">循环层 Recurrent</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/embeddings/">嵌入层 Embedding</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/merge/">融合层 Merge</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/advanced-activations/">高级激活层 Advanced Activations</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/normalization/">标准化层 Normalization</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/noise/">噪声层 Noise</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/wrappers/">层封装器 wrappers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/writing-your-own-keras-layers/">编写你自己的层</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">数据预处理</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../preprocessing/sequence/">序列预处理</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/text/">文本预处理</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/image/">图像预处理</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../losses/">损失函数 Losses</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../metrics/">评估标准 Metrics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../optimizers/">优化器 Optimizers</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">激活函数 Activations</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#_1">激活函数的用法</a></li>
    

    <li class="toctree-l2"><a href="#_2">预定义激活函数</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#softmax">softmax</a></li>
        
            <li><a class="toctree-l3" href="#elu">elu</a></li>
        
            <li><a class="toctree-l3" href="#selu">selu</a></li>
        
            <li><a class="toctree-l3" href="#softplus">softplus</a></li>
        
            <li><a class="toctree-l3" href="#softsign">softsign</a></li>
        
            <li><a class="toctree-l3" href="#relu">relu</a></li>
        
            <li><a class="toctree-l3" href="#tanh">tanh</a></li>
        
            <li><a class="toctree-l3" href="#sigmoid">sigmoid</a></li>
        
            <li><a class="toctree-l3" href="#hard_sigmoid">hard_sigmoid</a></li>
        
            <li><a class="toctree-l3" href="#exponential">exponential</a></li>
        
            <li><a class="toctree-l3" href="#linear">linear</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#_3">高级激活函数</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../callbacks/">回调函数 Callbacks</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../datasets/">常用数据集 Datasets</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../applications/">应用 Applications</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../backend/">后端 Backend</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../initializers/">初始化 Initializers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../regularizers/">正则化 Regularizers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../constraints/">约束 Constraints</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../visualization/">可视化 Visualization</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../scikit-learn-api/">Scikit-learn API</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../utils/">工具</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../contributing/">贡献</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">经典样例</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../examples/addition_rnn/">Addition RNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/babi_rnn/">Baby RNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/babi_memnn/">Baby MemNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn/">CIFAR-10 CNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn_capsule/">CIFAR-10 CNN-Capsule</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn_tfaugment2d/">CIFAR-10 CNN with augmentation (TF)</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_resnet/">CIFAR-10 ResNet</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/conv_filter_visualization/">Convolution filter visualization</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/image_ocr/">Image OCR</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/imdb_bidirectional_lstm/">Bidirectional LSTM</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Keras 中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>激活函数 Activations</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="_1">激活函数的用法</h2>
<p>激活函数可以通过设置单独的激活层实现，也可以在构造层对象时通过传递 <code>activation</code> 参数实现：</p>
<pre><code class="python">from keras.layers import Activation, Dense

model.add(Dense(64))
model.add(Activation('tanh'))
</code></pre>

<p>等价于：</p>
<pre><code class="python">model.add(Dense(64, activation='tanh'))
</code></pre>

<p>你也可以通过传递一个逐元素运算的 Theano/TensorFlow/CNTK 函数来作为激活函数：</p>
<pre><code class="python">from keras import backend as K

model.add(Dense(64, activation=K.tanh))
model.add(Activation(K.tanh))
</code></pre>

<h2 id="_2">预定义激活函数</h2>
<h3 id="softmax">softmax</h3>
<pre><code class="python">keras.activations.softmax(x, axis=-1)
</code></pre>

<p>Softmax 激活函数。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>：张量。</li>
<li><strong>axis</strong>：整数，代表softmax所作用的维度。</li>
</ul>
<p><strong>返回</strong></p>
<p>softmax 变换后的张量。</p>
<p><strong>异常</strong></p>
<ul>
<li><strong>ValueError</strong>：如果 <code>dim(x) == 1</code>。</li>
</ul>
<hr />
<h3 id="elu">elu</h3>
<pre><code class="python">keras.activations.elu(x, alpha=1.0)
</code></pre>

<p>指数线性单元。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>：张量。</li>
<li><strong>alpha</strong>：一个标量，表示负数部分的斜率。</li>
</ul>
<p><strong>返回</strong></p>
<p>线性指数激活：如果 <code>x &gt; 0</code>，返回值为 <code>x</code>；如果 <code>x &lt; 0</code> 返回值为 <code>alpha * (exp(x)-1)</code></p>
<p><strong>参考文献</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a></li>
</ul>
<hr />
<h3 id="selu">selu</h3>
<pre><code class="python">keras.activations.selu(x)
</code></pre>

<p>可伸缩的指数线性单元（SELU）。</p>
<p>SELU 等同于：<code>scale * elu(x, alpha)</code>，其中 alpha 和 scale 是预定义的常量。只要正确初始化权重（参见 <code>lecun_normal</code> 初始化方法）并且输入的数量「足够大」（参见参考文献获得更多信息），选择合适的 alpha 和 scale 的值，就可以在两个连续层之间保留输入的均值和方差。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>: 一个用来用于计算激活函数的张量或变量。</li>
</ul>
<p><strong>返回</strong></p>
<p>可伸缩的指数线性激活：<code>scale * elu(x, alpha)</code>。</p>
<p><strong>注意</strong></p>
<ul>
<li>与「lecun_normal」初始化方法一起使用。</li>
<li>与 dropout 的变种「AlphaDropout」一起使用。</li>
</ul>
<p><strong>参考文献</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a></li>
</ul>
<hr />
<h3 id="softplus">softplus</h3>
<pre><code class="python">keras.activations.softplus(x)
</code></pre>

<p>Softplus 激活函数。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>: 张量。</li>
</ul>
<p><strong>返回</strong></p>
<p>Softplus 激活：<code>log(exp(x) + 1)</code>。</p>
<hr />
<h3 id="softsign">softsign</h3>
<pre><code class="python">keras.activations.softsign(x)
</code></pre>

<p>Softsign 激活函数。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>: 张量。</li>
</ul>
<p><strong>返回</strong></p>
<p>Softsign 激活：<code>x / (abs(x) + 1)</code>。</p>
<hr />
<h3 id="relu">relu</h3>
<pre><code class="python">keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0.0)
</code></pre>

<p>整流线性单元。</p>
<p>使用默认值时，它返回逐元素的 <code>max(x, 0)</code>。</p>
<p>否则，它遵循：</p>
<ul>
<li>如果 <code>x &gt;= max_value</code>：<code>f(x) = max_value</code>，</li>
<li>如果 <code>threshold &lt;= x &lt; max_value</code>：<code>f(x) = x</code>，</li>
<li>否则：<code>f(x) = alpha * (x - threshold)</code>。</li>
</ul>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>: 张量。</li>
<li><strong>alpha</strong>：负数部分的斜率。默认为 0。</li>
<li><strong>max_value</strong>：输出的最大值。</li>
<li><strong>threshold</strong>: 浮点数。Thresholded activation 的阈值值。</li>
</ul>
<p><strong>返回</strong></p>
<p>一个张量。</p>
<hr />
<h3 id="tanh">tanh</h3>
<pre><code class="python">keras.activations.tanh(x)
</code></pre>

<p>双曲正切激活函数。</p>
<hr />
<h3 id="sigmoid">sigmoid</h3>
<pre><code class="python">sigmoid(x)
</code></pre>

<p>Sigmoid 激活函数。</p>
<hr />
<h3 id="hard_sigmoid">hard_sigmoid</h3>
<pre><code class="python">hard_sigmoid(x)
</code></pre>

<p>Hard sigmoid 激活函数。</p>
<p>计算速度比 sigmoid 激活函数更快。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>x</strong>: 张量。</li>
</ul>
<p><strong>返回</strong></p>
<p>Hard sigmoid 激活：</p>
<ul>
<li>如果 <code>x &lt; -2.5</code>，返回 0。</li>
<li>如果 <code>x &gt; 2.5</code>，返回 1。</li>
<li>如果 <code>-2.5 &lt;= x &lt;= 2.5</code>，返回 <code>0.2 * x + 0.5</code>。</li>
</ul>
<hr />
<h3 id="exponential">exponential</h3>
<pre><code class="python">keras.activations.exponential(x)
</code></pre>

<p>自然数指数激活函数。</p>
<hr />
<h3 id="linear">linear</h3>
<pre><code class="python">keras.activations.linear(x)
</code></pre>

<p>线性激活函数（即不做任何改变）</p>
<h2 id="_3">高级激活函数</h2>
<p>对于 Theano/TensorFlow/CNTK 不能表达的复杂激活函数，如含有可学习参数的激活函数，可通过<a href="../layers/advanced-activations/">高级激活函数</a>实现，可以在 <code>keras.layers.advanced_activations</code> 模块中找到。 这些高级激活函数包括 <code>PReLU</code> 和 <code>LeakyReLU</code>。</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../callbacks/" class="btn btn-neutral float-right" title="回调函数 Callbacks">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../optimizers/" class="btn btn-neutral" title="优化器 Optimizers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../optimizers/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../callbacks/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
