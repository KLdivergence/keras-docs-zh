<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>回调函数 Callbacks - Keras 中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u56de\u8c03\u51fd\u6570 Callbacks";
    var mkdocs_page_input_path = "callbacks.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Keras 中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">主页</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../why-use-keras/">为什么选择 Keras?</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">快速开始</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../getting-started/sequential-model-guide/">Sequential 顺序模型指引</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/functional-api-guide/">函数式 API 指引</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/faq/">FAQ 常见问题解答</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">模型</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../models/about-keras-models/">关于 Keras 模型</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/sequential/">Sequential 顺序模型 API</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/model/">函数式 API</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Layers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../layers/about-keras-layers/">关于 Keras 网络层</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/core/">核心网络层</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/convolutional/">卷积层 Convolutional</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/pooling/">池化层 Pooling</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/local/">局部连接层 Locally-connected</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/recurrent/">循环层 Recurrent</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/embeddings/">嵌入层 Embedding</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/merge/">融合层 Merge</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/advanced-activations/">高级激活层 Advanced Activations</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/normalization/">标准化层 Normalization</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/noise/">噪声层 Noise</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/wrappers/">层封装器 wrappers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/writing-your-own-keras-layers/">编写你自己的层</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">数据预处理</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../preprocessing/sequence/">序列预处理</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/text/">文本预处理</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/image/">图像预处理</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../losses/">损失函数 Losses</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../metrics/">评估标准 Metrics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../optimizers/">优化器 Optimizers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../activations/">激活函数 Activations</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">回调函数 Callbacks</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#_1">回调函数使用</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#callback">Callback</a></li>
        
            <li><a class="toctree-l3" href="#baselogger">BaseLogger</a></li>
        
            <li><a class="toctree-l3" href="#terminateonnan">TerminateOnNaN</a></li>
        
            <li><a class="toctree-l3" href="#progbarlogger">ProgbarLogger</a></li>
        
            <li><a class="toctree-l3" href="#history">History</a></li>
        
            <li><a class="toctree-l3" href="#modelcheckpoint">ModelCheckpoint</a></li>
        
            <li><a class="toctree-l3" href="#earlystopping">EarlyStopping</a></li>
        
            <li><a class="toctree-l3" href="#remotemonitor">RemoteMonitor</a></li>
        
            <li><a class="toctree-l3" href="#learningratescheduler">LearningRateScheduler</a></li>
        
            <li><a class="toctree-l3" href="#tensorboard">TensorBoard</a></li>
        
            <li><a class="toctree-l3" href="#reducelronplateau">ReduceLROnPlateau</a></li>
        
            <li><a class="toctree-l3" href="#csvlogger">CSVLogger</a></li>
        
            <li><a class="toctree-l3" href="#lambdacallback">LambdaCallback</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#_2">创建一个回调函数</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#_3">例: 记录损失历史</a></li>
        
            <li><a class="toctree-l3" href="#_4">例: 模型检查点</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../datasets/">常用数据集 Datasets</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../applications/">应用 Applications</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../backend/">后端 Backend</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../initializers/">初始化 Initializers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../regularizers/">正则化 Regularizers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../constraints/">约束 Constraints</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../visualization/">可视化 Visualization</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../scikit-learn-api/">Scikit-learn API</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../utils/">工具</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../contributing/">贡献</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">经典样例</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../examples/addition_rnn/">Addition RNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/babi_rnn/">Baby RNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/babi_memnn/">Baby MemNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn/">CIFAR-10 CNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn_capsule/">CIFAR-10 CNN-Capsule</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_cnn_tfaugment2d/">CIFAR-10 CNN with augmentation (TF)</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/cifar10_resnet/">CIFAR-10 ResNet</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/conv_filter_visualization/">Convolution filter visualization</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/image_ocr/">Image OCR</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples/imdb_bidirectional_lstm/">Bidirectional LSTM</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Keras 中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>回调函数 Callbacks</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="_1">回调函数使用</h2>
<p>回调函数是一个函数的合集，会在训练的阶段中所使用。你可以使用回调函数来查看训练模型的内在状态和统计。你可以传递一个列表的回调函数（作为 <code>callbacks</code> 关键字参数）到 <code>Sequential</code> 或 <code>Model</code> 类型的 <code>.fit()</code> 方法。在训练时，相应的回调函数的方法就会被在各自的阶段被调用。</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L148">[source]</a></span></p>
<h3 id="callback">Callback</h3>
<pre><code class="python">keras.callbacks.Callback()
</code></pre>

<p>用来组建新的回调函数的抽象基类。</p>
<p><strong>属性</strong></p>
<ul>
<li><strong>params</strong>: 字典。训练参数，
(例如，verbosity, batch size, number of epochs...)。</li>
<li><strong>model</strong>: <code>keras.models.Model</code> 的实例。
指代被训练模型。</li>
</ul>
<p>被回调函数作为参数的 <code>logs</code> 字典，它会含有于当前批量或训练轮相关数据的键。</p>
<p>目前，<code>Sequential</code> 模型类的 <code>.fit()</code> 方法会在传入到回调函数的 <code>logs</code> 里面包含以下的数据：</p>
<ul>
<li><strong>on_epoch_end</strong>: 包括 <code>acc</code> 和 <code>loss</code> 的日志， 也可以选择性的包括 <code>val_loss</code>（如果在 <code>fit</code> 中启用验证），和 <code>val_acc</code>（如果启用验证和监测精确值）。</li>
<li><strong>on_batch_begin</strong>: 包括 <code>size</code> 的日志，在当前批量内的样本数量。</li>
<li><strong>on_batch_end</strong>: 包括 <code>loss</code> 的日志，也可以选择性的包括 <code>acc</code>（如果启用监测精确值）。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L204">[source]</a></span></p>
<h3 id="baselogger">BaseLogger</h3>
<pre><code class="python">keras.callbacks.BaseLogger(stateful_metrics=None)
</code></pre>

<p>会积累训练轮平均评估的回调函数。</p>
<p>这个回调函数被自动应用到每一个 Keras 模型上面。</p>
<p><strong>参数</strong></p>
<p><strong>stateful_metrics</strong>: 可重复使用不应在一个 epoch 上平均的指标的字符串名称。
此列表中的度量标准将按原样记录在 <code>on_epoch_end</code> 中。
所有其他指标将在 <code>on_epoch_end</code> 中取平均值。</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L251">[source]</a></span></p>
<h3 id="terminateonnan">TerminateOnNaN</h3>
<pre><code class="python">keras.callbacks.TerminateOnNaN()
</code></pre>

<p>当遇到 NaN 损失会停止训练的回调函数。</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L264">[source]</a></span></p>
<h3 id="progbarlogger">ProgbarLogger</h3>
<pre><code class="python">keras.callbacks.ProgbarLogger(count_mode='samples', stateful_metrics=None)
</code></pre>

<p>会把评估以标准输出打印的回调函数。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>count_mode</strong>: "steps" 或者 "samples"。
进度条是否应该计数看见的样本或步骤（批量）。
<strong>stateful_metrics</strong>: 可重复使用不应在一个 epoch 上平均的指标的字符串名称。
此列表中的度量标准将按原样记录在 <code>on_epoch_end</code> 中。
所有其他指标将在 <code>on_epoch_end</code> 中取平均值。</li>
</ul>
<p><strong>异常</strong></p>
<ul>
<li><strong>ValueError</strong>: 如果 <code>count_mode</code></li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L341">[source]</a></span></p>
<h3 id="history">History</h3>
<pre><code class="python">keras.callbacks.History()
</code></pre>

<p>把所有事件都记录到 <code>History</code> 对象的回调函数。</p>
<p>这个回调函数被自动启用到每一个 Keras 模型。<code>History</code> 对象会被模型的 <code>fit</code> 方法返回。</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L360">[source]</a></span></p>
<h3 id="modelcheckpoint">ModelCheckpoint</h3>
<pre><code class="python">keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
</code></pre>

<p>在每个训练期之后保存模型。</p>
<p><code>filepath</code> 可以包括命名格式选项，可以由 <code>epoch</code> 的值和 <code>logs</code> 的键（由 <code>on_epoch_end</code> 参数传递）来填充。</p>
<p>例如：如果 <code>filepath</code> 是 <code>weights.{epoch:02d}-{val_loss:.2f}.hdf5</code>，
那么模型被保存的的文件名就会有训练轮数和验证损失。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>filepath</strong>: 字符串，保存模型的路径。</li>
<li><strong>monitor</strong>: 被监测的数据。</li>
<li><strong>verbose</strong>: 详细信息模式，0 或者 1 。</li>
<li><strong>save_best_only</strong>: 如果 <code>save_best_only=True</code>，
被监测数据的最佳模型就不会被覆盖。</li>
<li><strong>mode</strong>: {auto, min, max} 的其中之一。
如果 <code>save_best_only=True</code>，那么是否覆盖保存文件的决定就取决于被监测数据的最大或者最小值。
对于 <code>val_acc</code>，模式就会是 <code>max</code>，而对于 <code>val_loss</code>，模式就需要是 <code>min</code>，等等。
在 <code>auto</code> 模式中，方向会自动从被监测的数据的名字中判断出来。</li>
<li><strong>save_weights_only</strong>: 如果 True，那么只有模型的权重会被保存 (<code>model.save_weights(filepath)</code>)，
否则的话，整个模型会被保存 (<code>model.save(filepath)</code>)。</li>
<li><strong>period</strong>: 每个检查点之间的间隔（训练轮数）。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L460">[source]</a></span></p>
<h3 id="earlystopping">EarlyStopping</h3>
<pre><code class="python">keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)
</code></pre>

<p>当被监测的数量不再提升，则停止训练。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>monitor</strong>: 被监测的数据。</li>
<li><strong>min_delta</strong>: 在被监测的数据中被认为是提升的最小变化，
例如，小于 min_delta 的绝对变化会被认为没有提升。</li>
<li><strong>patience</strong>: 没有进步的训练轮数，在这之后训练就会被停止。</li>
<li><strong>verbose</strong>: 详细信息模式。</li>
<li><strong>mode</strong>: {auto, min, max} 其中之一。 在 <code>min</code> 模式中，
当被监测的数据停止下降，训练就会停止；在 <code>max</code>
模式中，当被监测的数据停止上升，训练就会停止；在 <code>auto</code>
模式中，方向会自动从被监测的数据的名字中判断出来。</li>
<li><strong>baseline</strong>: 要监控的数量的基准值。
如果模型没有显示基准的改善，训练将停止。</li>
<li><strong>restore_best_weights</strong>: 是否从具有监测数量的最佳值的时期恢复模型权重。
如果为 False，则使用在训练的最后一步获得的模型权重。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L574">[source]</a></span></p>
<h3 id="remotemonitor">RemoteMonitor</h3>
<pre><code class="python">keras.callbacks.RemoteMonitor(root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None, send_as_json=False)
</code></pre>

<p>将事件数据流到服务器的回调函数。</p>
<p>需要 <code>requests</code> 库。
事件被默认发送到 <code>root + '/publish/epoch/end/'</code>。
采用 HTTP POST ，其中的 <code>data</code> 参数是以 JSON 编码的事件数据字典。
如果 send_as_json 设置为 True，请求的 content type 是 application/json。否则，将在表单中发送序列化的 JSON。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>root</strong>: 字符串；目标服务器的根地址。</li>
<li><strong>path</strong>: 字符串；相对于 <code>root</code> 的路径，事件数据被送达的地址。</li>
<li><strong>field</strong>: 字符串；JSON ，数据被保存的领域。</li>
<li><strong>headers</strong>: 字典；可选自定义的 HTTP 的头字段。</li>
<li><strong>send_as_json</strong>: 布尔值；请求是否应该以 application/json 格式发送。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L633">[source]</a></span></p>
<h3 id="learningratescheduler">LearningRateScheduler</h3>
<pre><code class="python">keras.callbacks.LearningRateScheduler(schedule, verbose=0)
</code></pre>

<p>学习速率定时器。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>schedule</strong>: 一个函数，接受轮索引数作为输入（整数，从 0 开始迭代）
然后返回一个学习速率作为输出（浮点数）。</li>
<li><strong>verbose</strong>: 整数。 0：安静，1：更新信息。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L669">[source]</a></span></p>
<h3 id="tensorboard">TensorBoard</h3>
<pre><code class="python">keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')
</code></pre>

<p>Tensorboard 基本可视化。</p>
<p><a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">TensorBoard</a>
是由 Tensorflow 提供的一个可视化工具。</p>
<p>这个回调函数为 Tensorboard 编写一个日志，
这样你可以可视化测试和训练的标准评估的动态图像，
也可以可视化模型中不同层的激活值直方图。</p>
<p>如果你已经使用 pip 安装了 Tensorflow，你应该可以从命令行启动 Tensorflow：</p>
<pre><code class="sh">tensorboard --logdir=/full_path_to_your_logs
</code></pre>

<p><strong>参数</strong></p>
<ul>
<li><strong>log_dir</strong>: 用来保存被 TensorBoard 分析的日志文件的文件名。</li>
<li><strong>histogram_freq</strong>: 对于模型中各个层计算激活值和模型权重直方图的频率（训练轮数中）。
如果设置成 0 ，直方图不会被计算。对于直方图可视化的验证数据（或分离数据）一定要明确的指出。</li>
<li><strong>write_graph</strong>: 是否在 TensorBoard 中可视化图像。
如果 write_graph 被设置为 True，日志文件会变得非常大。</li>
<li><strong>write_grads</strong>: 是否在 TensorBoard  中可视化梯度值直方图。
<code>histogram_freq</code> 必须要大于 0 。</li>
<li><strong>batch_size</strong>: 用以直方图计算的传入神经元网络输入批的大小。</li>
<li><strong>write_images</strong>: 是否在 TensorBoard 中将模型权重以图片可视化。</li>
<li><strong>embeddings_freq</strong>: 被选中的嵌入层会被保存的频率（在训练轮中）。</li>
<li><strong>embeddings_layer_names</strong>: 一个列表，会被监测层的名字。
如果是 None 或空列表，那么所有的嵌入层都会被监测。</li>
<li><strong>embeddings_metadata</strong>: 一个字典，对应层的名字到保存有这个嵌入层元数据文件的名字。
查看 <a href="https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional">详情</a>
关于元数据的数据格式。
以防同样的元数据被用于所用的嵌入层，字符串可以被传入。</li>
<li><strong>embeddings_data</strong>: 要嵌入在 <code>embeddings_layer_names</code> 指定的层的数据。
Numpy 数组（如果模型有单个输入）或 Numpy 数组列表（如果模型有多个输入）。
<a href="https://www.tensorflow.org/programmers_guide/embedding">Learn ore about embeddings</a>。</li>
<li><strong>update_freq</strong>: <code>'batch'</code> 或 <code>'epoch'</code> 或 整数。当使用 <code>'batch'</code> 时，在每个 batch 之后将损失和评估值写入到 TensorBoard 中。同样的情况应用到 <code>'epoch'</code> 中。如果使用整数，例如 <code>10000</code>，这个回调会在每 10000 个样本之后将损失和评估值写入到 TensorBoard 中。注意，频繁地写入到 TensorBoard 会减缓你的训练。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1017">[source]</a></span></p>
<h3 id="reducelronplateau">ReduceLROnPlateau</h3>
<pre><code class="python">keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)
</code></pre>

<p>当标准评估停止提升时，降低学习速率。</p>
<p>当学习停止时，模型总是会受益于降低 2-10 倍的学习速率。
这个回调函数监测一个数据并且当这个数据在一定「有耐心」的训练轮之后还没有进步，
那么学习速率就会被降低。</p>
<p><strong>例子</strong></p>
<pre><code class="python">reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5, min_lr=0.001)
model.fit(X_train, Y_train, callbacks=[reduce_lr])
</code></pre>

<p><strong>参数</strong></p>
<ul>
<li><strong>monitor</strong>: 被监测的数据。</li>
<li><strong>factor</strong>: 学习速率被降低的因数。新的学习速率 = 学习速率 * 因数</li>
<li><strong>patience</strong>: 没有进步的训练轮数，在这之后训练速率会被降低。</li>
<li><strong>verbose</strong>: 整数。0：安静，1：更新信息。</li>
<li><strong>mode</strong>: {auto, min, max} 其中之一。如果是 <code>min</code> 模式，学习速率会被降低如果被监测的数据已经停止下降；
在 <code>max</code> 模式，学习塑料会被降低如果被监测的数据已经停止上升；
在 <code>auto</code> 模式，方向会被从被监测的数据中自动推断出来。</li>
<li><strong>min_delta</strong>: 对于测量新的最优化的阀值，只关注巨大的改变。</li>
<li><strong>cooldown</strong>: 在学习速率被降低之后，重新恢复正常操作之前等待的训练轮数量。</li>
<li><strong>min_lr</strong>: 学习速率的下边界。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1138">[source]</a></span></p>
<h3 id="csvlogger">CSVLogger</h3>
<pre><code class="python">keras.callbacks.CSVLogger(filename, separator=',', append=False)
</code></pre>

<p>把训练轮结果数据流到 csv 文件的回调函数。</p>
<p>支持所有可以被作为字符串表示的值，包括 1D 可迭代数据，例如，np.ndarray。</p>
<p><strong>例子</strong></p>
<pre><code class="python">csv_logger = CSVLogger('training.log')
model.fit(X_train, Y_train, callbacks=[csv_logger])
</code></pre>

<p><strong>参数</strong></p>
<ul>
<li><strong>filename</strong>: csv 文件的文件名，例如 'run/log.csv'。</li>
<li><strong>separator</strong>: 用来隔离 csv 文件中元素的字符串。</li>
<li><strong>append</strong>: True：如果文件存在则增加（可以被用于继续训练）。False：覆盖存在的文件。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1226">[source]</a></span></p>
<h3 id="lambdacallback">LambdaCallback</h3>
<pre><code class="python">keras.callbacks.LambdaCallback(on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None)
</code></pre>

<p>在训练进行中创建简单，自定义的回调函数的回调函数。</p>
<p>这个回调函数和匿名函数在合适的时间被创建。
需要注意的是回调函数要求位置型参数，如下：</p>
<ul>
<li><code>on_epoch_begin</code> 和 <code>on_epoch_end</code> 要求两个位置型的参数：
<code>epoch</code>, <code>logs</code></li>
<li><code>on_batch_begin</code> 和 <code>on_batch_end</code> 要求两个位置型的参数：
<code>batch</code>, <code>logs</code></li>
<li><code>on_train_begin</code> 和 <code>on_train_end</code> 要求一个位置型的参数：
<code>logs</code></li>
</ul>
<p><strong>参数</strong></p>
<ul>
<li><strong>on_epoch_begin</strong>: 在每轮开始时被调用。</li>
<li><strong>on_epoch_end</strong>: 在每轮结束时被调用。</li>
<li><strong>on_batch_begin</strong>: 在每批开始时被调用。</li>
<li><strong>on_batch_end</strong>: 在每批结束时被调用。</li>
<li><strong>on_train_begin</strong>: 在模型训练开始时被调用。</li>
<li><strong>on_train_end</strong>: 在模型训练结束时被调用。</li>
</ul>
<p><strong>例子</strong></p>
<pre><code class="python"># 在每一个批开始时，打印出批数。
batch_print_callback = LambdaCallback(
    on_batch_begin=lambda batch,logs: print(batch))

# 把训练轮损失数据流到 JSON 格式的文件。文件的内容
# 不是完美的 JSON 格式，但是时每一行都是 JSON 对象。
import json
json_log = open('loss_log.json', mode='wt', buffering=1)
json_logging_callback = LambdaCallback(
    on_epoch_end=lambda epoch, logs: json_log.write(
        json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\n'),
    on_train_end=lambda logs: json_log.close()
)

# 在完成模型训练之后，结束一些进程。
processes = ...
cleanup_callback = LambdaCallback(
    on_train_end=lambda logs: [
        p.terminate() for p in processes if p.is_alive()])

model.fit(...,
          callbacks=[batch_print_callback,
                     json_logging_callback,
                     cleanup_callback])
</code></pre>

<hr />
<h1 id="_2">创建一个回调函数</h1>
<p>你可以通过扩展 <code>keras.callbacks.Callback</code> 基类来创建一个自定义的回调函数。
通过类的属性 <code>self.model</code>，回调函数可以获得它所联系的模型。</p>
<p>下面是一个简单的例子，在训练时，保存一个列表的批量损失值：</p>
<pre><code class="python">class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
</code></pre>

<hr />
<h3 id="_3">例: 记录损失历史</h3>
<pre><code class="python">class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))

model = Sequential()
model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

history = LossHistory()
model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, callbacks=[history])

print(history.losses)
# 输出
'''
[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]
'''
</code></pre>

<hr />
<h3 id="_4">例: 模型检查点</h3>
<pre><code class="python">from keras.callbacks import ModelCheckpoint

model = Sequential()
model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

'''
如果验证损失下降， 那么在每个训练轮之后保存模型。
'''
checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)
model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../datasets/" class="btn btn-neutral float-right" title="常用数据集 Datasets">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../activations/" class="btn btn-neutral" title="激活函数 Activations"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../activations/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../datasets/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
